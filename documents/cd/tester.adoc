= **Lancez les tests automatisÃ©s**

Maintenant que lâ€™environnementÂ **staging**Â est dÃ©ployÃ©, il est possible de lancer des tests impossibles Ã  lancer lors de la phase dâ€™intÃ©gration continue. Dans ce chapitre, nous allons lancer unÂ **test de performance**, afin de mesurer les temps de rÃ©ponse de lâ€™application. Pour ce faire, vous allez utiliser **Apache Benchmark** pour simuler de la charge sur le serveur.

Ces tests peuvent Ãªtre de diffÃ©rents types.

== **DÃ©couvrez les tests dâ€™acceptance**

LesÂ **tests dâ€™acceptance**Â sont des tests formels exÃ©cutÃ©s pour vÃ©rifier si un systÃ¨me satisfait Ã  ses exigences opÃ©rationnelles. 


Ils exigent que lâ€™application entiÃ¨re soit opÃ©rationnelle et se concentrent sur la rÃ©plication des comportements des utilisateurs. 

Mais ils peuvent aussi aller plus loin, en mesurant la performance du systÃ¨me, et rejeter les changements si certains objectifs ne sont pas atteints.

Ces tests peuvent ÃªtreÂ **automatisÃ©s**, mais aussiÂ **manuels**, avec une Ã©quipe de test dÃ©diÃ©e qui regardera si le logiciel correspond au besoin.

Pour lancer des tests dâ€™acceptance, vous pourrez utiliserÂ **Confluence**,Â **FitNesse**Â ouÂ **Ranorex**.

== **DÃ©couvrez les tests de performance**

LesÂ **tests de performance**Â vÃ©rifient le comportement du systÃ¨me lorsquâ€™il est soumis Ã  une charge importante. Ces tests ne sont pas fonctionnels et peuvent prendre diffÃ©rentes formes pour comprendre la fiabilitÃ©, la stabilitÃ© et la disponibilitÃ© de la plateforme. Par exemple, il peut sâ€™agir dâ€™observer les temps de rÃ©ponse lors de lâ€™exÃ©cution dâ€™un grand nombre de requÃªtes, ou de voir comment le systÃ¨me se comporte avec une quantitÃ© importante de donnÃ©es.

Les tests de performance sont par nature assez coÃ»teux Ã  mettre en Å“uvre et Ã  exÃ©cuter, mais ils peuvent vous aider Ã  comprendre si de nouveaux changements vont dÃ©grader votre systÃ¨me.

Pour faire des tests de performance, vous pourrez utiliserÂ **JMeter**,Â **Apache Bench**Â ouÂ **Gatling**.

### **DÃ©couvrez les smoke tests**

LesÂ **smoke tests**Â sont des tests de base qui vÃ©rifient les fonctionnalitÃ©s de base de lâ€™application. Ils sont conÃ§us pour Ãªtre rapides Ã  exÃ©cuter et leur but est de vous donner lâ€™assurance que lesÂ **principales caractÃ©ristiques de votre systÃ¨me fonctionnent comme prÃ©vu**. Ils peuvent Ãªtre utiles juste aprÃ¨s une nouvelle build, pour dÃ©cider si vous pouvez ou non exÃ©cuter des tests plus coÃ»teux, ou juste aprÃ¨s un dÃ©ploiement pour sâ€™assurer que lâ€™application fonctionne correctement dans le nouvel environnement dÃ©ployÃ©.

Par exemple, les smoke tests peuvent sâ€™assurer que la base de donnÃ©es rÃ©pond et est correctement configurÃ©e, mais aussi que les diffÃ©rents composants sont prÃ©sents et envoient des donnÃ©es correctes, comme des API qui devraient rÃ©pondre un code HTTP 200 ou une page web qui devrait sâ€™afficher.

Pour vous assurer du bon fonctionnement de lâ€™application, vous pourrez utiliserÂ **Selenium**,Â **SoapUI**Â ouÂ **Cypress**.

### **DÃ©couvrez les tests de sÃ©curitÃ©**

LesÂ **tests de sÃ©curitÃ©**Â sont des tests qui dÃ©couvrent les vulnÃ©rabilitÃ©s du systÃ¨me et dÃ©terminent que les donnÃ©es et les ressources du systÃ¨me sont protÃ©gÃ©es contre dâ€™Ã©ventuels intrus. Ils garantissent que le systÃ¨me et lâ€™application logicielle sont exempts de toute menace ou tout risque pouvant entraÃ®ner une perte. Le test de sÃ©curitÃ© dâ€™un systÃ¨me vise Ã  trouver toutes les failles et faiblesses possibles du systÃ¨me qui pourraient entraÃ®ner la perte dâ€™informations ou de rÃ©putation de lâ€™organisation.

Pour faire des tests de sÃ©curitÃ©, vous pouvez utiliser **Wapiti**, **Snyk** ou **ZAP (Zed Attack Proxy) dâ€™OWASP**.

== **DÃ©couvrez les tests dâ€™Infrastructure-as-Code**

Les tests dâ€™**Infrastructure-as-Code**Â ressemblent fortement aux tests de sÃ©curitÃ© prÃ©cÃ©demment Ã©voquÃ©s. Ces tests vont scanner vos fichiers dâ€™Infrastructure-as-Code Ã  la recherche de vulnÃ©rabilitÃ©s connues et vous avertir le cas Ã©chÃ©ant.

Ces tests permettent aussi de dÃ©tecter des problÃ¨mes de configuration inhÃ©rents aux fichiers dâ€™Infrastructure-as-Code grÃ¢ce Ã  unÂ **linter**Â qui vous avertit si vos fichiers sont mal formatÃ©s ou contiennent des erreurs de configuration. 


Un linter est un outil dâ€™analyse de code qui permet de dÃ©tecter les erreurs et les problÃ¨mes de syntaxe.

Pour faire des tests dâ€™Infrastructure-as-Code, vous pouvez utiliserÂ **Gitlab**,Â **Checov**Â ouÂ **TFLint**.

Il faut alors ajouter de nouvelles lignes dans le fichier`.gitlab-ci.yml`, afin de lancer les tests de performance sur le nouvel environnement :

```
performance_job:
  stage: performance
  image: alpine
  services:
    - docker:dind
  variables:
    URL: http://$PLAYWD-8080.direct.labs.play-with-docker.com/
    DOCKER_HOST: tcp://docker:2375
  script:
    - apk add --no-cache curl docker-cli
    - x=1; while [[ "$(curl -s -o /dev/null -w ''%{http_code}'' http://$PLAYWD-8080.direct.labs.play-with-docker.com/)" != "200" || $x -le 60 ]]; do sleep 5; echo $(( x++ )); done || false
    - mkdir gitlab-exporter
    - wget -O ./gitlab-exporter/index.js https://gitlab.com/gitlab-org/gl-performance/raw/master/index.js
    - mkdir sitespeed-results
    - docker run --shm-size=1g --rm -v "$(pwd)":/sitespeed.io sitespeedio/sitespeed.io --plugins.add ./gitlab-exporter --outputFolder sitespeed-results $URL
    - mv sitespeed-results/data/performance.json performance.json
  artifacts:
    paths:
      - sitespeed-results/
    reports:
      performance: performance.json

```

Dans ce nouveau bloc, la syntaxe reste la mÃªme. Nous rÃ©cupÃ©rons dans un premier temps lâ€™utilitaire de test de performance dans le bloc`script`. Nous lanÃ§ons ensuite une application qui va se charger de tester notre site et dâ€™en extraire des mÃ©triques de performance. Ces mÃ©triques sont ensuite uploadÃ©es sur GitLab afin dâ€™Ãªtre accessibles.

Ensuite, modifiez aussi le dÃ©but du fichier afin dâ€™ajouter une nouvelle ligne dans le bloc`stages`:

```
stages:
  - build
  - test
  - quality
  - package
  - deploy
  - performance
  - security

```

Ã€ la suite des tests de performance, nous allons lancer unÂ **scan de sÃ©curitÃ©**Â des images prÃ©cÃ©demment packagÃ©es afin de savoir si nos images contiennent des failles de sÃ©curitÃ©. Nous allons pouvoir ensuite prendre des dÃ©cisions quant au dÃ©ploiement de nos images en production, basÃ©es sur le nombre de vulnÃ©rabilitÃ©s de lâ€™image. Par exemple, nous pouvons dÃ©cider de ne pas dÃ©ployer les images contenant une faille critique en production, mais de la dÃ©ployer mÃªme si dâ€™autres types de failles existent.

Voici les changements Ã  faire dans le`.gitlab-ci.yaml`afin de lancer un scan des images :

```
container_scanning:
  stage: security
  image:
    name: aquasec/trivy:latest
    entrypoint: [""]
  services:
    - docker:dind
  variables:
    GIT_STRATEGY: none
    TRIVY_USERNAME: "$CI_REGISTRY_USER"
    TRIVY_PASSWORD: "$CI_REGISTRY_PASSWORD"
    TRIVY_AUTH_URL: "$CI_REGISTRY"
    FULL_IMAGE_NAME: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG
    DOCKER_HOST: tcp://docker:2375
  script:
    - trivy image --clear-cache
    - trivy image --exit-code 0 --cache-dir .trivycache/ --no-progress --format template --template "@/contrib/gitlab.tpl"
        --output "$CI_PROJECT_DIR/gl-container-scanning-report.json" "$FULL_IMAGE_NAME"
    - trivy image --exit-code 0 --cache-dir .trivycache/ --no-progress "$FULL_IMAGE_NAME"
    - trivy image --exit-code 1 --cache-dir .trivycache/ --severity CRITICAL --no-progress "$FULL_IMAGE_NAME"
  cache:
    paths:
      - .trivycache/
  artifacts:
    when: always
    reports:
      container_scanning: gl-container-scanning-report.json

```

### **DÃ©ployez en environnement de production**

### **DÃ©ployez votre application en production**

Enfin, une fois lâ€™environnement deÂ **staging**Â dÃ©ployÃ© et testÃ©, il ne reste plus quâ€™Ã  dÃ©ployer lâ€™application sur lâ€™environnement de production. Pour cela, vous allez une nouvelle fois modifier le fichier`.gitlab-ci.yml`afin dâ€™ajouter lâ€™Ã©tape de mise en production :

```
deploy_prod_job:
  stage: deploy
  image: alpine
  script:
    - apk add --no-cache docker-cli-compose
    - export DOCKER_HOST=tcp://$PLAYWD.direct.labs.play-with-docker.com:2375
    - docker compose down
    - docker compose up -d
  environment:
    name: prod
    url: http://$PLAYWD-8080.direct.labs.play-with-docker.com
  when: manual

```

Dans cette Ã©tape, nous ajoutons le mot clÃ©`when: manual`afin de ne dÃ©ployer en production quâ€™avec lâ€™intervention dâ€™un Ãªtre humain. La validation est requise afin de savoir sâ€™il existe des erreurs lors du dÃ©ploiement surÂ **staging**. Si des erreurs existent, il nâ€™y aura alors pas de mise en production.

Sur votre pipeline de livraison continue, le dÃ©ploiement manuel est symbolisÃ© par lâ€™icÃ´ne â–¶ï¸ Ã  cÃ´tÃ© de lâ€™Ã©tape`deploy_prod`.

!https://user.oc-static.com/upload/2023/04/14/16814675155067_image37.png

Le dÃ©ploiement manuel sur GitLab CI

Ces erreurs seront analysÃ©es lors de la prochaine Ã©tape : leÂ **monitoring**.

### **DÃ©ployez avec des techniques avancÃ©es**

Enfin, une technique largement utilisÃ©e lors de lâ€™utilisation de la livraison continue est leÂ **Canary Release**.

> ğŸ¦ Le principe duÂ Canary ReleaseÂ est le mÃªme que celui qui Ã©tait utilisÃ© dans les mines de charbon. Ã€ lâ€™Ã©poque, les mineurs qui descendaient Ã  la mine plaÃ§aient un canari devant eux, au bout dâ€™une perche dans une cage. Si le canari mourait, cela voulait dire que lâ€™air Ã©tait non respirable et les mineurs avaient alors le temps de rebrousser chemin afin dâ€™Ã©viter un sort fatal.
> 

Le principe est le mÃªme dans le dÃ©ploiement : une partie seulement des utilisateurs va Ãªtre redirigÃ©e vers la nouvelle version de production, et si quelque chose se passe mal, il nâ€™y aura quâ€™une petite partie des utilisateurs qui sera impactÃ©e.

Pour le mettre en place sur notre projet, modifiez le fichier`.gitlab-ci.yml`en ajoutant un nouveau bloc`canary`:

```
canary_job:
  stage: canary
  image: alpine
  script:
    - apk add --no-cache docker-cli-compose
    - export DOCKER_HOST=tcp://$PLAYWD.direct.labs.play-with-docker.com:2375
    - docker compose down
    - docker compose up -d
  environment:
    name: prod
    url: http://$PLAYWD-8080.direct.labs.play-with-docker.com
  when: manual
  only:
    - main

```

Le principe ici est exactement le mÃªme que la production, la diffÃ©rence Ã©tant que le dÃ©ploiement en canary est dÃ©corrÃ©lÃ© de la production.

Ensuite, modifiez le dÃ©but du fichier afin que dans le bloc`stages`soit ajoutÃ©e lâ€™Ã©tape`canary`:

```
stages:
  - build
  - test
  - quality
  - package
  - canary
  - deploy
  - performance
  - security

```

Nous avons maintenant un environnement qui se dÃ©ploie en parallÃ¨le de la production et qui contient uniquement une sous-partie des utilisateurs. Cet environnement sera trÃ¨s utile afin de faire des analyses en temps rÃ©el du comportement de lâ€™application et de voir sâ€™il nâ€™y a pas dâ€™erreurs.

Le pipeline de livraison continue est dorÃ©navant complet, de la compilation du projet au dÃ©ploiement sur un environnement de staging.

Une autre technique existe aussi afin de pouvoir pousser en production des changements rapidement : leÂ **dÃ©ploiement Blue/Green**. Le principe de ce dÃ©ploiement est dâ€™intervertir grÃ¢ce Ã  un Load Balancer les environnements de staging et les environnements de production.

Dans un dÃ©ploiementÂ **Blue/Green**, une fois lâ€™environnement staging stabilisÃ© avec la nouvelle version de lâ€™application, il faut configurer le Load Balancer en frontal afin de rediriger le trafic de lâ€™ancienne production vers lâ€™environnement de staging. Ainsi, les utilisateurs seront automatiquement redirigÃ©s vers la nouvelle version de lâ€™application. Si jamais des erreurs applicatives surviennent, le retour en arriÃ¨re est facilitÃ©. Il suffira de configurer le Load Balancer de la nouvelle version applicative vers lâ€™ancienne production qui est stable.

Ces erreurs seront facilement dÃ©tectables grÃ¢ce au monitoring applicatif que nous verrons dans le cinquiÃ¨me chapitre de cette partie.

Enfin, avec un pipeline correctement configurÃ©, nous pouvons imaginer dÃ©ployer deux versions en parallÃ¨le de lâ€™application et tester quelle version est la plus efficace. Cette technique de dÃ©ploiement est appelÃ©eÂ **A/B testing**Â et permet de valider des hypothÃ¨ses dâ€™accessibilitÃ©, de nouvelles interfaces, ou alors de nouveaux modÃ¨les de Machine Learning.

!https://user.oc-static.com/upload/2023/04/18/16818249233945_2C3-2.png

ModÃ©lisation du A/B testing

### **En rÃ©sumÃ©**

- DÃ©ployer un environnement de staging permet de valider les changements faits dans lâ€™application dans un environnement isoproduction.
- Il existe plusieurs types de tests automatisÃ©s : les tests de performance, les tests dâ€™acceptance, les smoke tests, les tests dâ€™Infrastructure-as-Code et les tests de sÃ©curitÃ©.
- La mÃ©thode du Canary Release permet de dÃ©ployer une nouvelle version de production Ã  une partie seulement des utilisateurs de lâ€™application.

*Dans le prochain chapitre, vous dÃ©couvrirez le mÃ©tier de Site Reliability Engineer, comment maintenir en condition opÃ©rationnelle votre application avec les quatre signaux dorÃ©s et comment contrÃ´ler vos niveaux de service.*